{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anl3VwDHjL1V"
      },
      "source": [
        "# RAG ì‹¤ìŠµ\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "####ğŸ’¡ RAGë€?\n",
        "\n",
        "Retrieval-Augmented Generationì˜ ì•½ìë¡œ, LLMì—ê²Œ ê´€ë ¨ ë¬¸ì„œë¥¼ ë¨¼ì € ì°¾ì•„ì„œ (Retrieval) ì œê³µí•œ í›„ ë‹µë³€ì„ ìƒì„± (Generation)í•˜ê²Œ í•˜ëŠ” ê¸°ë²• <br/>ì´ë¥¼ í†µí•´ ìµœì‹  ì •ë³´ í™œìš©, ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ ì ìš©, ê·¸ë¦¬ê³  ê±°ì§“ ì •ë³´ ìƒì„± (Hallucination) ê°ì†Œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "<br/>\n",
        "\n",
        "####â­ï¸ í•™ìŠµ ëª©í‘œ\n",
        "ë³¸ ì‹¤ìŠµì—ì„œëŠ” ë‹¤ìŒì„ ë‹¨ê³„ë³„ë¡œ ì‹¤ìŠµí•©ë‹ˆë‹¤:\n",
        "1. **í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘**: Wikipediaì—ì„œ ë‹¤ì–‘í•œ ì£¼ì œì˜ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°\n",
        "2. **ì„ë² ë”© ì´í•´**: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì • ì²´í—˜\n",
        "3. **ë²¡í„°DB ì €ì¥**: ChromaDBë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
        "4. **RAG íŒŒì´í”„ë¼ì¸**: ì§ˆì˜ â†’ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±\n",
        "5. **Hallucination ë¹„êµ**: RAGê°€ ì™œ í•„ìš”í•œì§€ ì‹¤í—˜ìœ¼ë¡œ ì¦ëª…\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UreJIGWKkxwP"
      },
      "source": [
        "## 0. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜, API í‚¤ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "aoCKXViahUcr"
      },
      "outputs": [],
      "source": [
        "!pip install openai==1.54.3 -q\n",
        "!pip install httpx==0.27.0 -q\n",
        "!pip install chromadb==0.5.11 -q\n",
        "!pip install wikipedia-api==0.7.1 -q\n",
        "!pip install scikit-learn matplotlib -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ieIrnoNklAZe"
      },
      "outputs": [],
      "source": [
        "import wikipediaapi\n",
        "import os\n",
        "os.environ[\"CHROMA_TELEMETRY_DISABLED\"] = \"true\"\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from openai import OpenAI\n",
        "from typing import List, Dict\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# openai API key ì„¤ì •\n",
        "OPENAI_API_KEY = \"YOUR_API_KEY\" #TODO: ì‹¤ì œ APIí‚¤ë¡œ êµì²´í•´ì£¼ì„¸ìš”\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSSK3lfnwdPs"
      },
      "source": [
        "## 1. Wikipediaì—ì„œ í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘\n",
        "\n",
        "ì£¼ì œì„ ì •: ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ ë²”ìš©ì„±ì„ í…ŒìŠ¤íŠ¸\n",
        "- **ìœ ì‚¬ ì£¼ì œ ê·¸ë£¹ (AI ê´€ë ¨)**: ì¸ê³µì§€ëŠ¥, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹\n",
        "- **ë‹¤ì–‘í•œ ë„ë©”ì¸**: í”„ë¡œê·¸ë˜ë°, ë¸”ë¡ì²´ì¸, ê³¼í•™, í™˜ê²½, ë¬¸í™”, ìŠ¤í¬ì¸ , ì˜ˆìˆ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWIDqkiZnJSW",
        "outputId": "104556a1-c149-45fa-b1d3-9ae23c3e3bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1/10] 'ì¸ê³µì§€ëŠ¥' ìˆ˜ì§‘ ì™„ë£Œ (349ì)\n",
            "[ 2/10] 'ë¨¸ì‹ ëŸ¬ë‹' ìˆ˜ì§‘ ì™„ë£Œ (441ì)\n",
            "[ 3/10] 'ë”¥ëŸ¬ë‹' ìˆ˜ì§‘ ì™„ë£Œ (600ì)\n",
            "[ 4/10] 'í•œêµ­ ìš”ë¦¬' ìˆ˜ì§‘ ì™„ë£Œ (600ì)\n",
            "[ 5/10] 'ì˜¬ë¦¼í”½' ìˆ˜ì§‘ ì™„ë£Œ (600ì)\n",
            "[ 6/10] 'ë¥´ë„¤ìƒìŠ¤' ìˆ˜ì§‘ ì™„ë£Œ (550ì)\n",
            "[ 7/10] 'íŒŒì´ì¬' ìˆ˜ì§‘ ì™„ë£Œ (382ì)\n",
            "[ 8/10] 'ë¸”ë¡ì²´ì¸' ìˆ˜ì§‘ ì™„ë£Œ (437ì)\n",
            "[ 9/10] 'ì–‘ì ì»´í“¨íŒ…' ìˆ˜ì§‘ ì™„ë£Œ (600ì)\n",
            "[10/10] 'ê¸°í›„ë³€í™”' ìˆ˜ì§‘ ì™„ë£Œ (600ì)\n",
            "============================================================\n",
            "\n",
            " ì´ 10ê°œì˜ ë¬¸ì„œê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Wikipedia API ì´ˆê¸°í™”\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    user_agent='RAG-Practice/1.0',\n",
        "    language='ko'\n",
        ")\n",
        "\n",
        "# ìˆ˜ì§‘í•  ì£¼ì œë“¤\n",
        "topics = [\n",
        "    # === ìœ ì‚¬ ì£¼ì œ: AI ê´€ë ¨ ===\n",
        "    \"ì¸ê³µì§€ëŠ¥\",\n",
        "    \"ë¨¸ì‹ ëŸ¬ë‹\",\n",
        "    \"ë”¥ëŸ¬ë‹\",\n",
        "\n",
        "    # === ë‹¤ì–‘í•œ ë„ë©”ì¸ ===\n",
        "    \"í•œêµ­ ìš”ë¦¬\",\n",
        "    \"ì˜¬ë¦¼í”½\",\n",
        "    \"ë¥´ë„¤ìƒìŠ¤\",\n",
        "    \"íŒŒì´ì¬\",\n",
        "    \"ë¸”ë¡ì²´ì¸\",\n",
        "    \"ì–‘ì ì»´í“¨íŒ…\",\n",
        "    \"ê¸°í›„ë³€í™”\",\n",
        "]\n",
        "\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i, topic in enumerate(topics, 1):\n",
        "    try:\n",
        "        page = wiki.page(topic)\n",
        "        if page.exists():\n",
        "            # ìš”ì•½ë¬¸ ì‚¬ìš© (ìµœëŒ€ 600ì)\n",
        "            summary = page.summary[:600] if len(page.summary) > 600 else page.summary\n",
        "\n",
        "            documents.append({\n",
        "                \"id\": f\"doc_{len(documents)}\",\n",
        "                \"topic\": topic,\n",
        "                \"content\": summary,\n",
        "                \"category\": \"AI\" if topic in [\"ì¸ê³µì§€ëŠ¥\", \"ë¨¸ì‹ ëŸ¬ë‹\", \"ë”¥ëŸ¬ë‹\"] else \"Other\",\n",
        "                \"source\": f\"https://ko.wikipedia.org/wiki/{topic.replace(' ', '_')}\"\n",
        "            })\n",
        "\n",
        "            print(f\"[{i:2d}/10] '{topic}' ìˆ˜ì§‘ ì™„ë£Œ ({len(summary)}ì)\")\n",
        "        else:\n",
        "            print(f\"[{i:2d}/10] '{topic}' í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[{i:2d}/10] '{topic}' ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n ì´ {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHQzHSY1w8lO",
        "outputId": "d7f18ebe-5b67-42c9-b378-15c7f22b2547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ë¬¸ì„œ 1: ì¸ê³µì§€ëŠ¥\n",
            "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
            "ì¸ê³µì§€ëŠ¥(äººå·¥æ™ºèƒ½, ì˜ì–´: artificial intelligence, AI)ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥, ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥ì„ ì¸ê³µì ìœ¼ë¡œ êµ¬í˜„í•˜ë ¤ëŠ” ì»´í“¨í„° ê³¼í•™ì˜ ì„¸ë¶€ë¶„ì•¼ ì¤‘ í•˜ë‚˜ì´ë‹¤. ...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ë¬¸ì„œ 2: ë¨¸ì‹ ëŸ¬ë‹\n",
            "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
            "ê¸°ê³„ í•™ìŠµ(æ©Ÿæ¢°å­¸ç¿’) ë˜ëŠ” ë¨¸ì‹  ëŸ¬ë‹(ì˜ì–´: machine learning, ML)ì€ ê²½í—˜ì„ í†µí•´ ìë™ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ì»´í“¨í„° ì•Œê³ ë¦¬ì¦˜ì˜ ì—°êµ¬ì´ë‹¤. ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ 'ë¯¸ë˜ë¥¼ ì˜ˆ...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ë¬¸ì„œ 3: ë”¥ëŸ¬ë‹\n",
            "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
            "ì‹¬ì¸µ í•™ìŠµ(æ·±å±¤å­¸ç¿’) ë˜ëŠ” ë”¥ ëŸ¬ë‹(ì˜ì–´: deep structured learning, deep learning ë˜ëŠ” hierarchical learning)ì€ ì—¬ëŸ¬ 'ë¹„ì„ í˜• ë³€...\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ìˆ˜ì§‘ëœ ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°\n",
        "for i, doc in enumerate(documents[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"ë¬¸ì„œ {i}: {doc['topic']}\")\n",
        "    print(f\"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "    print(f\"{doc['content'][:100]}...\")\n",
        "    print(f\"{'='*80}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNTVDFVx9vJ"
      },
      "source": [
        "## 2. ì„ë² ë”© ìƒì„±\n",
        "\n",
        "- ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
        "- ì»´í“¨í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì´í•´í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—, ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•´ ìˆ˜í•™ì ìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "- ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë¬¸ì¥ë“¤ì€ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MDBzGGHlxg-J"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Text\n",
        "def get_embedding(text: str, model=\"text-embedding-3-small\") -> List[float]:\n",
        "    \"\"\"\n",
        "    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜\n",
        "\n",
        "    Args:\n",
        "        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸\n",
        "        model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸\n",
        "\n",
        "    Returns:\n",
        "        1536ì°¨ì›ì˜ ë²¡í„° (ì‹¤ìˆ˜ ë¦¬ìŠ¤íŠ¸)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.embeddings.create(\n",
        "            input=text,\n",
        "            model=model\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPyVpTfyiQ5",
        "outputId": "ee0371ea-f56e-48cb-d320-d54ac4356ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1/10] 'ì¸ê³µì§€ëŠ¥' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 2/10] 'ë¨¸ì‹ ëŸ¬ë‹' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 3/10] 'ë”¥ëŸ¬ë‹' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 4/10] 'í•œêµ­ ìš”ë¦¬' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 5/10] 'ì˜¬ë¦¼í”½' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 6/10] 'ë¥´ë„¤ìƒìŠ¤' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 7/10] 'íŒŒì´ì¬' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 8/10] 'ë¸”ë¡ì²´ì¸' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[ 9/10] 'ì–‘ì ì»´í“¨íŒ…' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "[10/10] 'ê¸°í›„ë³€í™”' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ ì„ë² ë”© ìƒì„±\n",
        "for i, doc in enumerate(documents, 1):\n",
        "  embedding = get_embedding(doc[\"content\"])\n",
        "  if embedding:\n",
        "      doc[\"embedding\"] = embedding\n",
        "      print(f\"[{i:2d}/{len(documents)}] '{doc['topic']}' ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: {len(embedding)})\")\n",
        "\n",
        "documents = [doc for doc in documents if 'embedding' in doc]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWb4vXDA2wzL"
      },
      "source": [
        "(ì°¸ê³ ) ì„ë² ë”© ë²¡í„° ì¶œë ¥í•´ë³´ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0xUNEDjy0iC",
        "outputId": "30149b16-0bcd-4adf-c508-89d91351143d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] ì¸ê³µì§€ëŠ¥ | dim=1536\n",
            "[0.020815, 0.024216, -0.006495, 0.021805, 0.027076, -0.052677, -0.005375, 0.057031, 0.009706, 0.006252, 0.018063, -0.013952, -0.023964, -0.048108, 0.029847, -0.029397, -0.046309, -0.016938, 0.068437, -0.027832 ...]\n",
            "----------------------------------------------------------------------\n",
            "[2] ë¨¸ì‹ ëŸ¬ë‹ | dim=1536\n",
            "[-0.007226, 0.033005, -0.008111, -0.012604, 0.045193, -0.023912, 0.022945, 0.031999, 0.001929, 0.030702, 0.006099, -0.032966, -0.045851, -0.003195, 0.017963, 0.005509, 0.006109, -0.024280, 0.028729, -0.015719 ...]\n",
            "----------------------------------------------------------------------\n",
            "[3] ë”¥ëŸ¬ë‹ | dim=1536\n",
            "[-0.006711, -0.004804, -0.025430, 0.004809, 0.013380, -0.047315, 0.015026, 0.060526, -0.059766, 0.019658, 0.021674, -0.003305, -0.022075, -0.012135, 0.056559, -0.017738, 0.017622, 0.001696, 0.031783, -0.017242 ...]\n",
            "----------------------------------------------------------------------\n",
            "[4] í•œêµ­ ìš”ë¦¬ | dim=1536\n",
            "[-0.018430, 0.018691, -0.038127, -0.009555, 0.053270, -0.044292, -0.008018, 0.027361, -0.037773, -0.004619, 0.048688, -0.032726, 0.010337, 0.000025, -0.011651, -0.043249, -0.044702, 0.001091, 0.001100, -0.011138 ...]\n",
            "----------------------------------------------------------------------\n",
            "[5] ì˜¬ë¦¼í”½ | dim=1536\n",
            "[0.006278, 0.023814, 0.023368, -0.004409, 0.011839, -0.006623, -0.013264, -0.006986, -0.031978, -0.007287, 0.000051, -0.034887, -0.032618, -0.020672, 0.038281, 0.018345, -0.053756, 0.027266, -0.013652, 0.001612 ...]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def format_vec(vec, n=20, precision=6, show_sign=False):\n",
        "    \"\"\"ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ì˜ë¼ì„œ í‘œì‹œ\"\"\"\n",
        "    if show_sign:\n",
        "        fmt = lambda v: f\"{v:+.{precision}f}\"\n",
        "    else:\n",
        "        fmt = lambda v: f\"{v:.{precision}f}\"\n",
        "    head = \", \".join(fmt(v) for v in vec[:n])\n",
        "    tail = \" ...\" if len(vec) > n else \"\"\n",
        "    return \"[\" + head + tail + \"]\"\n",
        "\n",
        "# ì—¬ëŸ¬ ê°œ ë¯¸ë¦¬ë³´ê¸° (ì˜ˆ: ìƒìœ„ 5ê°œ ë¬¸ì„œ)\n",
        "k = min(5, len(documents))\n",
        "for i, doc in enumerate(documents[:k], 1):\n",
        "    vec = doc.get(\"embedding\")\n",
        "    if not vec:\n",
        "        print(f\"[{i}] {doc.get('topic','(no topic)')} â†’ embedding ì—†ìŒ\")\n",
        "        continue\n",
        "    print(f\"[{i}] {doc['topic']} | dim={len(vec)}\")\n",
        "    print(format_vec(vec, n=20, precision=6, show_sign=False))\n",
        "    print(\"-\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky-XWPvd212H"
      },
      "source": [
        "(ì°¸ê³ ) ì„ë² ë”© ê°„ ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76xZxJYm1EW-",
        "outputId": "65840b21-c21d-48b1-a168-5914f37681f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ ë¹„êµ\n",
            "\n",
            "AI ê´€ë ¨ ë¬¸ì„œë“¤ (ìœ ì‚¬í•œ ì£¼ì œ)\n",
            "--------------------------------------------------------------------------------\n",
            "   'ì¸ê³µì§€ëŠ¥' <-> 'ë¨¸ì‹ ëŸ¬ë‹':    ìœ ì‚¬ë„: 0.4972\n",
            "   'ì¸ê³µì§€ëŠ¥' <-> 'ë”¥ëŸ¬ë‹':    ìœ ì‚¬ë„: 0.3810\n",
            "   'ë¨¸ì‹ ëŸ¬ë‹' <-> 'ë”¥ëŸ¬ë‹':    ìœ ì‚¬ë„: 0.5580\n",
            "\n",
            "AI vs ë‹¤ë¥¸ ì£¼ì œ (ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œ)\n",
            "--------------------------------------------------------------------------------\n",
            "   'ì¸ê³µì§€ëŠ¥' <-> 'í•œêµ­ ìš”ë¦¬:    ìœ ì‚¬ë„: 0.0735'\n",
            "   'ì¸ê³µì§€ëŠ¥' <-> 'ì˜¬ë¦¼í”½:    ìœ ì‚¬ë„: 0.0975'\n",
            "   'ì¸ê³µì§€ëŠ¥' <-> 'ë¥´ë„¤ìƒìŠ¤:    ìœ ì‚¬ë„: 0.0607'\n",
            "   'ë¨¸ì‹ ëŸ¬ë‹' <-> 'í•œêµ­ ìš”ë¦¬:    ìœ ì‚¬ë„: 0.1451'\n",
            "   'ë¨¸ì‹ ëŸ¬ë‹' <-> 'ì˜¬ë¦¼í”½:    ìœ ì‚¬ë„: 0.2056'\n",
            "   'ë¨¸ì‹ ëŸ¬ë‹' <-> 'ë¥´ë„¤ìƒìŠ¤:    ìœ ì‚¬ë„: 0.0751'\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "\n",
        "    Returns:\n",
        "        -1 ~ 1 ì‚¬ì´ì˜ ê°’ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)\n",
        "    \"\"\"\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "\n",
        "print(\"ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ ë¹„êµ\\n\")\n",
        "\n",
        "# AI ê´€ë ¨ ë¬¸ì„œë“¤ë¼ë¦¬ì˜ ìœ ì‚¬ë„\n",
        "ai_docs = [doc for doc in documents if doc[\"category\"] == \"AI\"]\n",
        "if len(ai_docs) >= 2:\n",
        "    print(\"AI ê´€ë ¨ ë¬¸ì„œë“¤ (ìœ ì‚¬í•œ ì£¼ì œ)\")\n",
        "    print(\"-\"*80)\n",
        "    for i in range(len(ai_docs)):\n",
        "        for j in range(i+1, len(ai_docs)):\n",
        "            sim = cosine_similarity(ai_docs[i][\"embedding\"], ai_docs[j][\"embedding\"])\n",
        "            print(f\"   '{ai_docs[i]['topic']}' <-> '{ai_docs[j]['topic']}':    ìœ ì‚¬ë„: {sim:.4f}\")\n",
        "    print(\"\")\n",
        "\n",
        "# ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ ë¬¸ì„œë“¤ì˜ ìœ ì‚¬ë„\n",
        "other_docs = [doc for doc in documents if doc[\"category\"] != \"AI\"][:7]\n",
        "if len(ai_docs) > 0 and len(other_docs) > 0:\n",
        "    print(\"AI vs ë‹¤ë¥¸ ì£¼ì œ (ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œ)\")\n",
        "    print(\"-\"*80)\n",
        "    for i in range(min(2, len(ai_docs))):\n",
        "        for j in range(min(3, len(other_docs))):\n",
        "            sim = cosine_similarity(ai_docs[i][\"embedding\"], other_docs[j][\"embedding\"])\n",
        "            print(f\"   '{ai_docs[i]['topic']}' <-> '{other_docs[j]['topic']}:    ìœ ì‚¬ë„: {sim:.4f}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgRRg4w4QNW"
      },
      "source": [
        "## 3. VectorDB ì €ì¥\n",
        "- ì¼ë°˜ ë°ì´í„°ë² ì´ìŠ¤ëŠ” í…ìŠ¤íŠ¸ ê²€ìƒ‰ë§Œ ê°€ëŠ¥í•˜ì§€ë§Œ, ë²¡í„°ë””ë¹„ëŠ”\n",
        "  1. ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "  2. ìˆ˜ë°±ë§Œê°œì˜ ë²¡í„° ì¤‘ì—ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
        "  3. ë©”íƒ€ë°ì´í„°(ì¶œì²˜) ë“±ë„ í•¨ê»˜ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJz8thlk3DiF",
        "outputId": "580b9d7b-834c-45bf-e6fe-fb103d195f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì»¬ë ‰ì…˜ ì´ë¦„: rag_practice\n",
            "ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: 10\n",
            "ë©”íƒ€ë°ì´í„°: topic, category, source\n"
          ]
        }
      ],
      "source": [
        "# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "from chromadb.config import Settings\n",
        "import logging\n",
        "logging.getLogger(\"chromadb.telemetry\").setLevel(logging.CRITICAL)\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.CRITICAL)\n",
        "\n",
        "chroma_client = chromadb.Client(Settings(\n",
        "    anonymized_telemetry=False,\n",
        "))\n",
        "\n",
        "# ì´ì „ ì»¬ë ‰ì…˜ì´ ìˆë‹¤ë©´ ì‚­ì œ\n",
        "try:\n",
        "    chroma_client.delete_collection(name=\"rag_practice\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±\n",
        "collection = chroma_client.create_collection(\n",
        "    name=\"rag_practice\",\n",
        "    metadata={\"description\": \"RAG ì‹¤ìŠµì„ ìœ„í•œ Wikipedia ë¬¸ì„œ ì»¬ë ‰ì…˜\"}\n",
        ")\n",
        "\n",
        "\n",
        "if len(documents) > 0:\n",
        "    # ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥\n",
        "    collection.add(\n",
        "        ids=[doc[\"id\"] for doc in documents],\n",
        "        embeddings=[doc[\"embedding\"] for doc in documents],\n",
        "        documents=[doc[\"content\"] for doc in documents],\n",
        "        metadatas=[\n",
        "            {\n",
        "                \"topic\": doc[\"topic\"],\n",
        "                \"category\": doc[\"category\"],\n",
        "                \"source\": doc[\"source\"]\n",
        "            }\n",
        "            for doc in documents\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"ì»¬ë ‰ì…˜ ì´ë¦„: {collection.name}\")\n",
        "    print(f\"ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {collection.count()}\")\n",
        "    print(f\"ë©”íƒ€ë°ì´í„°: topic, category, source\")\n",
        "else:\n",
        "    print(\"ì €ì¥í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJUpu6yC6i-1"
      },
      "source": [
        "(ì°¸ê³ ) Chunking í¬ê¸° ì„ íƒ ê¸°ì¤€\n",
        "\n",
        "- chunkingì´ í•„ìš”í•œ ì´ìœ \n",
        "  1. **LLMì˜ ì…ë ¥ ì œí•œ**: í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ê°€ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤\n",
        "  2. **ê²€ìƒ‰ ì •í™•ë„**: ì‘ì€ ì¡°ê°ì´ ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ë‹´ê³  ìˆì–´ ê²€ìƒ‰ì´ ì •í™•í•©ë‹ˆë‹¤\n",
        "  3. **ë¹„ìš© íš¨ìœ¨**: í•„ìš”í•œ ë¶€ë¶„ë§Œ LLMì— ì „ë‹¬í•˜ì—¬ ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤\n",
        "\n",
        "- chunking í¬ê¸° ì„ íƒ ê¸°ì¤€\n",
        "\n",
        "| Chunk í¬ê¸° | ì¥ì  | ë‹¨ì  | ì í•©í•œ ê²½ìš° |\n",
        "|-----------|------|------|------------|\n",
        "| **ì‘ìŒ** (100-300ì) | ê²€ìƒ‰ ì •í™•ë„ ë†’ìŒ<br>ë¹„ìš© íš¨ìœ¨ì  | ë¬¸ë§¥ ì†ì‹¤ ê°€ëŠ¥<br>ë„ˆë¬´ ë§ì€ chunk | êµ¬ì²´ì ì¸ ì‚¬ì‹¤ ê²€ìƒ‰<br>(ì˜ˆ: Q&A, FAQ) |\n",
        "| **ì¤‘ê°„** (300-600ì) | ê· í˜•ì¡íŒ ì„ íƒ<br>ë¬¸ë§¥ ìœ ì§€ | - | **ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ê¶Œì¥** |\n",
        "| **í¼** (600-1000ì) | ë¬¸ë§¥ ìœ ì§€ ì˜ ë¨ | ê²€ìƒ‰ ì •í™•ë„ í•˜ë½<br>ë¹„ìš© ì¦ê°€ | ë¬¸ë§¥ì´ ì¤‘ìš”í•œ ê²½ìš°<br>(ì˜ˆ: ì†Œì„¤, ë…¼ë¬¸) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKs75WV7Nbb"
      },
      "source": [
        "## 4. RAG Pipeline êµ¬í˜„\n",
        "\n",
        "\n",
        "```\n",
        "1. ì‚¬ìš©ì ì§ˆì˜\n",
        "      â¬‡ï¸\n",
        "2. ì§ˆì˜ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
        "      â¬‡ï¸\n",
        "3. Vector DBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (Top-K)\n",
        "      â¬‡ï¸\n",
        "4. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ LLMì— ì „ë‹¬\n",
        "      â¬‡ï¸\n",
        "5. LLMì´ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sn7IOPRW7MCq"
      },
      "outputs": [],
      "source": [
        "def rag_query(query: str, top_k: int = 3, show_details: bool = True):\n",
        "    \"\"\"\n",
        "    RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ì§ˆì˜ì— ë‹µë³€\n",
        "    \"\"\"\n",
        "    if collection.count() == 0:\n",
        "        print(\"Vector DBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"ì‚¬ìš©ì ì§ˆì˜: {query}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # STEP 1: ì§ˆì˜ ì„ë² ë”© ìƒì„±\n",
        "    if show_details:\n",
        "        print(\"1. Queryë¥¼ ë²¡í„°ë¡œ ë³€í™˜ ì¤‘...\")\n",
        "\n",
        "    query_embedding = get_embedding(query)\n",
        "    if not query_embedding:\n",
        "        print(\"ì§ˆì˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨\")\n",
        "        return None\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: {len(query_embedding)})\\n\")\n",
        "\n",
        "    # STEP 2: Vector DBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\n",
        "    if show_details:\n",
        "        print(f\"2ï¸. Vector DBì—ì„œ Top-{top_k} ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\")\n",
        "\n",
        "    try:\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=min(top_k, collection.count())\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\" ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    if not results['documents'][0]:\n",
        "        print(\" ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   {len(results['documents'][0])}ê°œ ë¬¸ì„œ ë°œê²¬\\n\")\n",
        "        print(\"   ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "        print(\"   \" + \"-\"*76)\n",
        "\n",
        "        for i, (doc, metadata, distance) in enumerate(zip(\n",
        "            results['documents'][0],\n",
        "            results['metadatas'][0],\n",
        "            results['distances'][0]\n",
        "        ), 1):\n",
        "            print(f\"\\n   [{i}ìœ„] {metadata.get('topic', 'Unknown')}\")\n",
        "            print(f\"        ì¹´í…Œê³ ë¦¬: {metadata.get('category', 'Unknown')}\")\n",
        "            print(f\"        ìœ ì‚¬ë„ ê±°ë¦¬: {distance:.4f}\")\n",
        "            print(f\"        ë‚´ìš©: {doc[:100]}...\")\n",
        "\n",
        "        print(\"\\n   \" + \"-\"*76)\n",
        "\n",
        "    # STEP 3: ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"[ë¬¸ì„œ {i+1}: {metadata.get('topic', 'Unknown')}]\\n{doc}\"\n",
        "        for i, (doc, metadata) in enumerate(zip(\n",
        "            results['documents'][0],\n",
        "            results['metadatas'][0]\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # STEP 4: LLM ë‹µë³€ ìƒì„±\n",
        "    if show_details:\n",
        "        print(\"\\n3. LLMì´ ë‹µë³€ ìƒì„± ì¤‘...\\n\")\n",
        "\n",
        "    try:\n",
        "        prompt = f\"\"\"ë‹¤ìŒì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œë“¤ì…ë‹ˆë‹¤:\n",
        "\n",
        "{context}\n",
        "\n",
        "ìœ„ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
        "ë‹µë³€í•  ë•ŒëŠ” ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ì§ˆë¬¸: {query}\n",
        "\n",
        "ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ì •í™•íˆ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\"\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"{'='*80}\")\n",
        "            print(\"LLM ë‹µë³€\")\n",
        "            print(f\"{'='*80}\")\n",
        "            print(answer)\n",
        "            print(f\"\\n{'='*80}\\n\")\n",
        "\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"retrieved_docs\": results,\n",
        "            \"answer\": answer,\n",
        "            \"context\": context\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"LLM ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u39YWq3D9Dpx"
      },
      "source": [
        "## 5. RAG vs No-RAG ì‹¤í—˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GrBvlNAe9AkL"
      },
      "outputs": [],
      "source": [
        "# ì‹¤í—˜ìš© ì§ˆë¬¸\n",
        "test_question = \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ êµ¬ì²´ì ì¸ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO0Y82wO9KsV"
      },
      "source": [
        "### 1) No-RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24a4vCbF9J0S",
        "outputId": "1bc174bd-4fae-4f87-9a02-a75fd28ece7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NO-RAG\n",
            "================================================================================\n",
            "ì§ˆë¬¸: ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ êµ¬ì²´ì ì¸ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
            "\n",
            "ë‹µë³€:\n",
            "--------------------------------------------------------------------------------\n",
            "ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)ê³¼ ë”¥ëŸ¬ë‹(Deep Learning)ì€ ì¸ê³µì§€ëŠ¥(AI) ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ë‘ ê°€ì§€ ê°œë…ì…ë‹ˆë‹¤. ì´ ë‘˜ì€ ì„œë¡œ ê´€ë ¨ì´ ìˆì§€ë§Œ, ëª‡ ê°€ì§€ ì¤‘ìš”í•œ ì°¨ì´ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "### 1. ì •ì˜\n",
            "- **ë¨¸ì‹ ëŸ¬ë‹**: ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì˜ ì§‘í•©ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì€ ì£¼ë¡œ íŠ¹ì§•(feature)ì„ ìˆ˜ë™ìœ¼ë¡œ ì„ íƒí•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
            "- **ë”¥ëŸ¬ë‹**: ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ í•˜ìœ„ ë¶„ì•¼ë¡œ, ì¸ê³µì‹ ê²½ë§(Artificial Neural Networks)ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ì—¬ëŸ¬ ì¸µì˜ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
            "\n",
            "### 2. ë°ì´í„° ì²˜ë¦¬\n",
            "- **ë¨¸ì‹ ëŸ¬ë‹**: ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ ì¼ë°˜ì ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„°ì— ì˜ ì‘ë™í•˜ë©°, íŠ¹ì§• ì„ íƒ ë° ì „ì²˜ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, SVM(Support Vector Machine), ê²°ì • íŠ¸ë¦¬(Decision Tree), ëœë¤ í¬ë ˆìŠ¤íŠ¸(Random Forest) ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
            "- **ë”¥ëŸ¬ë‹**: ë”¥ëŸ¬ë‹ì€ ë¹„êµ¬ì¡°í™”ëœ ë°ì´í„°(ì˜ˆ: ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ìŒì„± ë“±)ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ê°•ë ¥í•©ë‹ˆë‹¤. ì‹ ê²½ë§ì€ ë°ì´í„°ì˜ ë³µì¡í•œ íŒ¨í„´ì„ ìë™ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "### 3. ëª¨ë¸ì˜ ë³µì¡ì„±\n",
            "- **ë¨¸ì‹ ëŸ¬ë‹**: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨í•˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ ëª‡ ê°œì˜ ì¸µê³¼ íŒŒë¼ë¯¸í„°ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ë”°ë¼ì„œ í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ê³ , í•´ì„ì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
            "- **ë”¥ëŸ¬ë‹**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ˜ì‹­ ê°œì—ì„œ ìˆ˜ë°± ê°œì˜ ì¸µì„ ê°€ì§ˆ ìˆ˜ ìˆìœ¼ë©°, ë§¤ìš° ë³µì¡í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ëŒ€ëŸ‰ì˜ ë°ì´í„°ì™€ ê³„ì‚° ìì›ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "\n",
            "### 4. í•™ìŠµ ë°ì´í„°ì˜ ì–‘\n",
            "- **ë¨¸ì‹ ëŸ¬ë‹**: ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œë„ ì˜ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ìˆ˜ì²œ ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤.\n",
            "- **ë”¥ëŸ¬ë‹**: ë”¥ëŸ¬ë‹ì€ ëŒ€ëŸ‰ì˜ ë°ì´í„°(ìˆ˜ë§Œ ê°œ ì´ìƒì˜ ë°ì´í„° í¬ì¸íŠ¸)ê°€ í•„ìš”\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def no_rag_query(query: str):\n",
        "    \"\"\"RAG ì—†ì´ LLMì—ê²Œ ì§ì ‘ ì§ˆë¬¸\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"NO-RAG\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"ì§ˆë¬¸: {query}\\n\")\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content\n",
        "        print(\"ë‹µë³€:\")\n",
        "        print(\"-\"*80)\n",
        "        print(answer)\n",
        "        print(\"=\"*80)\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "no_rag_answer = no_rag_query(test_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8sJKiB79P9A"
      },
      "source": [
        "### 2) With RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1KZ9G5E9N1d",
        "outputId": "c7e0378b-328a-4650-ba48-891e498101b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ì‚¬ìš©ì ì§ˆì˜: ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ êµ¬ì²´ì ì¸ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
            "================================================================================\n",
            "\n",
            "1. Queryë¥¼ ë²¡í„°ë¡œ ë³€í™˜ ì¤‘...\n",
            "   ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: 1536)\n",
            "\n",
            "2ï¸. Vector DBì—ì„œ Top-3 ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\n",
            "   3ê°œ ë¬¸ì„œ ë°œê²¬\n",
            "\n",
            "   ê²€ìƒ‰ ê²°ê³¼:\n",
            "   ----------------------------------------------------------------------------\n",
            "\n",
            "   [1ìœ„] ë”¥ëŸ¬ë‹\n",
            "        ì¹´í…Œê³ ë¦¬: AI\n",
            "        ìœ ì‚¬ë„ ê±°ë¦¬: 1.3589\n",
            "        ë‚´ìš©: ì‹¬ì¸µ í•™ìŠµ(æ·±å±¤å­¸ç¿’) ë˜ëŠ” ë”¥ ëŸ¬ë‹(ì˜ì–´: deep structured learning, deep learning ë˜ëŠ” hierarchical learning)ì€ ì—¬ëŸ¬ 'ë¹„ì„ í˜• ë³€...\n",
            "\n",
            "   [2ìœ„] ë¨¸ì‹ ëŸ¬ë‹\n",
            "        ì¹´í…Œê³ ë¦¬: AI\n",
            "        ìœ ì‚¬ë„ ê±°ë¦¬: 1.4972\n",
            "        ë‚´ìš©: ê¸°ê³„ í•™ìŠµ(æ©Ÿæ¢°å­¸ç¿’) ë˜ëŠ” ë¨¸ì‹  ëŸ¬ë‹(ì˜ì–´: machine learning, ML)ì€ ê²½í—˜ì„ í†µí•´ ìë™ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ì»´í“¨í„° ì•Œê³ ë¦¬ì¦˜ì˜ ì—°êµ¬ì´ë‹¤. ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ 'ë¯¸ë˜ë¥¼ ì˜ˆ...\n",
            "\n",
            "   [3ìœ„] ì–‘ì ì»´í“¨íŒ…\n",
            "        ì¹´í…Œê³ ë¦¬: Other\n",
            "        ìœ ì‚¬ë„ ê±°ë¦¬: 1.5997\n",
            "        ë‚´ìš©: ì–‘ì ì»´í“¨í„°(quantum computer, ë¬¸í™”ì–´: ëŸ‰ì ì½¤í“¨í„°)ëŠ” ì–½í˜(entanglement)ì´ë‚˜ ì¤‘ì²©(superposition) ê°™ì€ ì–‘ìì—­í•™ì ì¸ í˜„ìƒì„ í™œìš©í•˜ì—¬ ìë£Œë¥¼ ì²˜...\n",
            "\n",
            "   ----------------------------------------------------------------------------\n",
            "\n",
            "3. LLMì´ ë‹µë³€ ìƒì„± ì¤‘...\n",
            "\n",
            "================================================================================\n",
            "LLM ë‹µë³€\n",
            "================================================================================\n",
            "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ êµ¬ì²´ì ì¸ ì°¨ì´ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
            "\n",
            "1. **ì •ì˜**:\n",
            "   - ë¨¸ì‹ ëŸ¬ë‹(ë¬¸ì„œ 2): ê²½í—˜ì„ í†µí•´ ìë™ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ì»´í“¨í„° ì•Œê³ ë¦¬ì¦˜ì˜ ì—°êµ¬ë¡œ, ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
            "   - ë”¥ëŸ¬ë‹(ë¬¸ì„œ 1): ì—¬ëŸ¬ ë¹„ì„ í˜• ë³€í™˜ê¸°ë²•ì˜ ì¡°í•©ì„ í†µí•´ ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¥¼ ì‹œë„í•˜ëŠ” ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ì§‘í•©ìœ¼ë¡œ, ì£¼ë¡œ ì‚¬ëŒì˜ ì‚¬ê³ ë°©ì‹ì„ ì»´í“¨í„°ì—ê²Œ ê°€ë¥´ì¹˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤.\n",
            "\n",
            "2. **êµ¬ì¡°**:\n",
            "   - ë¨¸ì‹ ëŸ¬ë‹: ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜(ì˜ˆ: ê²°ì • íŠ¸ë¦¬, ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë“±)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
            "   - ë”¥ëŸ¬ë‹: ì£¼ë¡œ ì‹¬ì¸µ ì‹ ê²½ë§(deep neural networks)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
            "\n",
            "3. **ë°ì´í„° ì²˜ë¦¬**:\n",
            "   - ë¨¸ì‹ ëŸ¬ë‹: ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œë„ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„°ì˜ í‘œí˜„(representation)ê³¼ ì¼ë°˜í™”(generalization)ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.\n",
            "   - ë”¥ëŸ¬ë‹: ëŒ€ëŸ‰ì˜ ë°ì´í„°ê°€ í•„ìš”í•˜ë©°, ë°ì´í„°ì˜ í‘œí˜„ì„ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ë” ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
            "\n",
            "4. **ì‘ìš© ë¶„ì•¼**:\n",
            "   - ë¨¸ì‹ ëŸ¬ë‹: ë¬¸ì ì¸ì‹, ìŠ¤íŒ¸ í•„í„°ë§ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ë©ë‹ˆë‹¤.\n",
            "   - ë”¥ëŸ¬ë‹: ì»´í“¨í„° ë¹„ì „, ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ìµœì²¨ë‹¨ ë¶„ì•¼ì— ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
            "\n",
            "ì´ëŸ¬í•œ ì°¨ì´ì ë“¤ì€ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì´ ì„œë¡œ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  í•™ìŠµí•˜ëŠ” ë°©ë²•ì— ê¸°ì¸í•©ë‹ˆë‹¤.\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rag_result = rag_query(test_question, top_k=3, show_details=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
