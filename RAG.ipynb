{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anl3VwDHjL1V"
      },
      "source": [
        "# RAG 실습\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "####💡 RAG란?\n",
        "\n",
        "Retrieval-Augmented Generation의 약자로, LLM에게 관련 문서를 먼저 찾아서 (Retrieval) 제공한 후 답변을 생성 (Generation)하게 하는 기법 <br/>이를 통해 최신 정보 활용, 도메인 특화 지식 적용, 그리고 거짓 정보 생성 (Hallucination) 감소 효과를 얻을 수 있습니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "####⭐️ 학습 목표\n",
        "본 실습에서는 다음을 단계별로 실습합니다:\n",
        "1. **텍스트 데이터 수집**: Wikipedia에서 다양한 주제의 문서 가져오기\n",
        "2. **임베딩 이해**: 텍스트를 벡터로 변환하는 과정 체험\n",
        "3. **벡터DB 저장**: ChromaDB를 사용한 효율적인 검색 시스템 구축\n",
        "4. **RAG 파이프라인**: 질의 → 검색 → 답변 생성\n",
        "5. **Hallucination 비교**: RAG가 왜 필요한지 실험으로 증명\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UreJIGWKkxwP"
      },
      "source": [
        "## 0. 필요한 라이브러리 설치, API 키 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "aoCKXViahUcr"
      },
      "outputs": [],
      "source": [
        "!pip install openai==1.54.3 -q\n",
        "!pip install httpx==0.27.0 -q\n",
        "!pip install chromadb==0.5.11 -q\n",
        "!pip install wikipedia-api==0.7.1 -q\n",
        "!pip install scikit-learn matplotlib -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ieIrnoNklAZe"
      },
      "outputs": [],
      "source": [
        "import wikipediaapi\n",
        "import os\n",
        "os.environ[\"CHROMA_TELEMETRY_DISABLED\"] = \"true\"\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from openai import OpenAI\n",
        "from typing import List, Dict\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# openai API key 설정\n",
        "OPENAI_API_KEY = \"YOUR_API_KEY\" #TODO: 실제 API키로 교체해주세요\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSSK3lfnwdPs"
      },
      "source": [
        "## 1. Wikipedia에서 텍스트 데이터 수집\n",
        "\n",
        "주제선정: 다양한 도메인에서 데이터를 수집하여 RAG 시스템의 범용성을 테스트\n",
        "- **유사 주제 그룹 (AI 관련)**: 인공지능, 머신러닝, 딥러닝\n",
        "- **다양한 도메인**: 프로그래밍, 블록체인, 과학, 환경, 문화, 스포츠, 예술"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWIDqkiZnJSW",
        "outputId": "104556a1-c149-45fa-b1d3-9ae23c3e3bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1/10] '인공지능' 수집 완료 (349자)\n",
            "[ 2/10] '머신러닝' 수집 완료 (441자)\n",
            "[ 3/10] '딥러닝' 수집 완료 (600자)\n",
            "[ 4/10] '한국 요리' 수집 완료 (600자)\n",
            "[ 5/10] '올림픽' 수집 완료 (600자)\n",
            "[ 6/10] '르네상스' 수집 완료 (550자)\n",
            "[ 7/10] '파이썬' 수집 완료 (382자)\n",
            "[ 8/10] '블록체인' 수집 완료 (437자)\n",
            "[ 9/10] '양자 컴퓨팅' 수집 완료 (600자)\n",
            "[10/10] '기후변화' 수집 완료 (600자)\n",
            "============================================================\n",
            "\n",
            " 총 10개의 문서가 수집되었습니다.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Wikipedia API 초기화\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    user_agent='RAG-Practice/1.0',\n",
        "    language='ko'\n",
        ")\n",
        "\n",
        "# 수집할 주제들\n",
        "topics = [\n",
        "    # === 유사 주제: AI 관련 ===\n",
        "    \"인공지능\",\n",
        "    \"머신러닝\",\n",
        "    \"딥러닝\",\n",
        "\n",
        "    # === 다양한 도메인 ===\n",
        "    \"한국 요리\",\n",
        "    \"올림픽\",\n",
        "    \"르네상스\",\n",
        "    \"파이썬\",\n",
        "    \"블록체인\",\n",
        "    \"양자 컴퓨팅\",\n",
        "    \"기후변화\",\n",
        "]\n",
        "\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i, topic in enumerate(topics, 1):\n",
        "    try:\n",
        "        page = wiki.page(topic)\n",
        "        if page.exists():\n",
        "            # 요약문 사용 (최대 600자)\n",
        "            summary = page.summary[:600] if len(page.summary) > 600 else page.summary\n",
        "\n",
        "            documents.append({\n",
        "                \"id\": f\"doc_{len(documents)}\",\n",
        "                \"topic\": topic,\n",
        "                \"content\": summary,\n",
        "                \"category\": \"AI\" if topic in [\"인공지능\", \"머신러닝\", \"딥러닝\"] else \"Other\",\n",
        "                \"source\": f\"https://ko.wikipedia.org/wiki/{topic.replace(' ', '_')}\"\n",
        "            })\n",
        "\n",
        "            print(f\"[{i:2d}/10] '{topic}' 수집 완료 ({len(summary)}자)\")\n",
        "        else:\n",
        "            print(f\"[{i:2d}/10] '{topic}' 페이지를 찾을 수 없습니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[{i:2d}/10] '{topic}' 수집 실패: {str(e)}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n 총 {len(documents)}개의 문서가 수집되었습니다.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHQzHSY1w8lO",
        "outputId": "d7f18ebe-5b67-42c9-b378-15c7f22b2547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "문서 1: 인공지능\n",
            "내용 미리보기:\n",
            "인공지능(人工智能, 영어: artificial intelligence, AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나이다. ...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "문서 2: 머신러닝\n",
            "내용 미리보기:\n",
            "기계 학습(機械學習) 또는 머신 러닝(영어: machine learning, ML)은 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구이다. 방대한 데이터를 분석해 '미래를 예...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "문서 3: 딥러닝\n",
            "내용 미리보기:\n",
            "심층 학습(深層學習) 또는 딥 러닝(영어: deep structured learning, deep learning 또는 hierarchical learning)은 여러 '비선형 변...\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# 수집된 문서 내용 미리보기\n",
        "for i, doc in enumerate(documents[:3], 1):  # 처음 3개만 표시\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"문서 {i}: {doc['topic']}\")\n",
        "    print(f\"내용 미리보기:\")\n",
        "    print(f\"{doc['content'][:100]}...\")\n",
        "    print(f\"{'='*80}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNTVDFVx9vJ"
      },
      "source": [
        "## 2. 임베딩 생성\n",
        "\n",
        "- 임베딩은 텍스트를 숫자 벡터로 변환하는 과정입니다.\n",
        "- 컴퓨터는 텍스트를 직접 이해할 수 없기 때문에, 숫자 벡터로 변환해 수학적으로 유사도를 계산할 수 있어야 합니다.\n",
        "- 의미가 비슷한 문장들은 벡터 공간에서 가까이 위치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MDBzGGHlxg-J"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Text\n",
        "def get_embedding(text: str, model=\"text-embedding-3-small\") -> List[float]:\n",
        "    \"\"\"\n",
        "    OpenAI API를 사용하여 텍스트를 임베딩 벡터로 변환\n",
        "\n",
        "    Args:\n",
        "        text: 임베딩할 텍스트\n",
        "        model: 사용할 임베딩 모델\n",
        "\n",
        "    Returns:\n",
        "        1536차원의 벡터 (실수 리스트)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.embeddings.create(\n",
        "            input=text,\n",
        "            model=model\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"임베딩 생성 실패: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPyVpTfyiQ5",
        "outputId": "ee0371ea-f56e-48cb-d320-d54ac4356ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1/10] '인공지능' 임베딩 완료 (차원: 1536)\n",
            "[ 2/10] '머신러닝' 임베딩 완료 (차원: 1536)\n",
            "[ 3/10] '딥러닝' 임베딩 완료 (차원: 1536)\n",
            "[ 4/10] '한국 요리' 임베딩 완료 (차원: 1536)\n",
            "[ 5/10] '올림픽' 임베딩 완료 (차원: 1536)\n",
            "[ 6/10] '르네상스' 임베딩 완료 (차원: 1536)\n",
            "[ 7/10] '파이썬' 임베딩 완료 (차원: 1536)\n",
            "[ 8/10] '블록체인' 임베딩 완료 (차원: 1536)\n",
            "[ 9/10] '양자 컴퓨팅' 임베딩 완료 (차원: 1536)\n",
            "[10/10] '기후변화' 임베딩 완료 (차원: 1536)\n"
          ]
        }
      ],
      "source": [
        "# 모든 문서에 대해 임베딩 생성\n",
        "for i, doc in enumerate(documents, 1):\n",
        "  embedding = get_embedding(doc[\"content\"])\n",
        "  if embedding:\n",
        "      doc[\"embedding\"] = embedding\n",
        "      print(f\"[{i:2d}/{len(documents)}] '{doc['topic']}' 임베딩 완료 (차원: {len(embedding)})\")\n",
        "\n",
        "documents = [doc for doc in documents if 'embedding' in doc]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWb4vXDA2wzL"
      },
      "source": [
        "(참고) 임베딩 벡터 출력해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0xUNEDjy0iC",
        "outputId": "30149b16-0bcd-4adf-c508-89d91351143d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] 인공지능 | dim=1536\n",
            "[0.020815, 0.024216, -0.006495, 0.021805, 0.027076, -0.052677, -0.005375, 0.057031, 0.009706, 0.006252, 0.018063, -0.013952, -0.023964, -0.048108, 0.029847, -0.029397, -0.046309, -0.016938, 0.068437, -0.027832 ...]\n",
            "----------------------------------------------------------------------\n",
            "[2] 머신러닝 | dim=1536\n",
            "[-0.007226, 0.033005, -0.008111, -0.012604, 0.045193, -0.023912, 0.022945, 0.031999, 0.001929, 0.030702, 0.006099, -0.032966, -0.045851, -0.003195, 0.017963, 0.005509, 0.006109, -0.024280, 0.028729, -0.015719 ...]\n",
            "----------------------------------------------------------------------\n",
            "[3] 딥러닝 | dim=1536\n",
            "[-0.006711, -0.004804, -0.025430, 0.004809, 0.013380, -0.047315, 0.015026, 0.060526, -0.059766, 0.019658, 0.021674, -0.003305, -0.022075, -0.012135, 0.056559, -0.017738, 0.017622, 0.001696, 0.031783, -0.017242 ...]\n",
            "----------------------------------------------------------------------\n",
            "[4] 한국 요리 | dim=1536\n",
            "[-0.018430, 0.018691, -0.038127, -0.009555, 0.053270, -0.044292, -0.008018, 0.027361, -0.037773, -0.004619, 0.048688, -0.032726, 0.010337, 0.000025, -0.011651, -0.043249, -0.044702, 0.001091, 0.001100, -0.011138 ...]\n",
            "----------------------------------------------------------------------\n",
            "[5] 올림픽 | dim=1536\n",
            "[0.006278, 0.023814, 0.023368, -0.004409, 0.011839, -0.006623, -0.013264, -0.006986, -0.031978, -0.007287, 0.000051, -0.034887, -0.032618, -0.020672, 0.038281, 0.018345, -0.053756, 0.027266, -0.013652, 0.001612 ...]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def format_vec(vec, n=20, precision=6, show_sign=False):\n",
        "    \"\"\"리스트를 문자열로 잘라서 표시\"\"\"\n",
        "    if show_sign:\n",
        "        fmt = lambda v: f\"{v:+.{precision}f}\"\n",
        "    else:\n",
        "        fmt = lambda v: f\"{v:.{precision}f}\"\n",
        "    head = \", \".join(fmt(v) for v in vec[:n])\n",
        "    tail = \" ...\" if len(vec) > n else \"\"\n",
        "    return \"[\" + head + tail + \"]\"\n",
        "\n",
        "# 여러 개 미리보기 (예: 상위 5개 문서)\n",
        "k = min(5, len(documents))\n",
        "for i, doc in enumerate(documents[:k], 1):\n",
        "    vec = doc.get(\"embedding\")\n",
        "    if not vec:\n",
        "        print(f\"[{i}] {doc.get('topic','(no topic)')} → embedding 없음\")\n",
        "        continue\n",
        "    print(f\"[{i}] {doc['topic']} | dim={len(vec)}\")\n",
        "    print(format_vec(vec, n=20, precision=6, show_sign=False))\n",
        "    print(\"-\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky-XWPvd212H"
      },
      "source": [
        "(참고) 임베딩 간 유사도 계산하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76xZxJYm1EW-",
        "outputId": "65840b21-c21d-48b1-a168-5914f37681f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서 간 유사도 비교\n",
            "\n",
            "AI 관련 문서들 (유사한 주제)\n",
            "--------------------------------------------------------------------------------\n",
            "   '인공지능' <-> '머신러닝':    유사도: 0.4972\n",
            "   '인공지능' <-> '딥러닝':    유사도: 0.3810\n",
            "   '머신러닝' <-> '딥러닝':    유사도: 0.5580\n",
            "\n",
            "AI vs 다른 주제 (서로 다른 주제)\n",
            "--------------------------------------------------------------------------------\n",
            "   '인공지능' <-> '한국 요리:    유사도: 0.0735'\n",
            "   '인공지능' <-> '올림픽:    유사도: 0.0975'\n",
            "   '인공지능' <-> '르네상스:    유사도: 0.0607'\n",
            "   '머신러닝' <-> '한국 요리:    유사도: 0.1451'\n",
            "   '머신러닝' <-> '올림픽:    유사도: 0.2056'\n",
            "   '머신러닝' <-> '르네상스:    유사도: 0.0751'\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    두 벡터의 코사인 유사도 계산\n",
        "\n",
        "    Returns:\n",
        "        -1 ~ 1 사이의 값 (1에 가까울수록 유사)\n",
        "    \"\"\"\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "\n",
        "print(\"문서 간 유사도 비교\\n\")\n",
        "\n",
        "# AI 관련 문서들끼리의 유사도\n",
        "ai_docs = [doc for doc in documents if doc[\"category\"] == \"AI\"]\n",
        "if len(ai_docs) >= 2:\n",
        "    print(\"AI 관련 문서들 (유사한 주제)\")\n",
        "    print(\"-\"*80)\n",
        "    for i in range(len(ai_docs)):\n",
        "        for j in range(i+1, len(ai_docs)):\n",
        "            sim = cosine_similarity(ai_docs[i][\"embedding\"], ai_docs[j][\"embedding\"])\n",
        "            print(f\"   '{ai_docs[i]['topic']}' <-> '{ai_docs[j]['topic']}':    유사도: {sim:.4f}\")\n",
        "    print(\"\")\n",
        "\n",
        "# 서로 다른 카테고리 문서들의 유사도\n",
        "other_docs = [doc for doc in documents if doc[\"category\"] != \"AI\"][:7]\n",
        "if len(ai_docs) > 0 and len(other_docs) > 0:\n",
        "    print(\"AI vs 다른 주제 (서로 다른 주제)\")\n",
        "    print(\"-\"*80)\n",
        "    for i in range(min(2, len(ai_docs))):\n",
        "        for j in range(min(3, len(other_docs))):\n",
        "            sim = cosine_similarity(ai_docs[i][\"embedding\"], other_docs[j][\"embedding\"])\n",
        "            print(f\"   '{ai_docs[i]['topic']}' <-> '{other_docs[j]['topic']}:    유사도: {sim:.4f}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgRRg4w4QNW"
      },
      "source": [
        "## 3. VectorDB 저장\n",
        "- 일반 데이터베이스는 텍스트 검색만 가능하지만, 벡터디비는\n",
        "  1. 의미적으로 유사한 문서를 빠르게 찾을 수 있습니다.\n",
        "  2. 수백만개의 벡터 중에서도 효율적으로 검색합니다.\n",
        "  3. 메타데이터(출처) 등도 함께 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJz8thlk3DiF",
        "outputId": "580b9d7b-834c-45bf-e6fe-fb103d195f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "컬렉션 이름: rag_practice\n",
            "저장된 문서 수: 10\n",
            "메타데이터: topic, category, source\n"
          ]
        }
      ],
      "source": [
        "# ChromaDB 클라이언트 초기화\n",
        "from chromadb.config import Settings\n",
        "import logging\n",
        "logging.getLogger(\"chromadb.telemetry\").setLevel(logging.CRITICAL)\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.CRITICAL)\n",
        "\n",
        "chroma_client = chromadb.Client(Settings(\n",
        "    anonymized_telemetry=False,\n",
        "))\n",
        "\n",
        "# 이전 컬렉션이 있다면 삭제\n",
        "try:\n",
        "    chroma_client.delete_collection(name=\"rag_practice\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 새 컬렉션 생성\n",
        "collection = chroma_client.create_collection(\n",
        "    name=\"rag_practice\",\n",
        "    metadata={\"description\": \"RAG 실습을 위한 Wikipedia 문서 컬렉션\"}\n",
        ")\n",
        "\n",
        "\n",
        "if len(documents) > 0:\n",
        "    # 벡터와 메타데이터 저장\n",
        "    collection.add(\n",
        "        ids=[doc[\"id\"] for doc in documents],\n",
        "        embeddings=[doc[\"embedding\"] for doc in documents],\n",
        "        documents=[doc[\"content\"] for doc in documents],\n",
        "        metadatas=[\n",
        "            {\n",
        "                \"topic\": doc[\"topic\"],\n",
        "                \"category\": doc[\"category\"],\n",
        "                \"source\": doc[\"source\"]\n",
        "            }\n",
        "            for doc in documents\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"컬렉션 이름: {collection.name}\")\n",
        "    print(f\"저장된 문서 수: {collection.count()}\")\n",
        "    print(f\"메타데이터: topic, category, source\")\n",
        "else:\n",
        "    print(\"저장할 문서가 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJUpu6yC6i-1"
      },
      "source": [
        "(참고) Chunking 크기 선택 기준\n",
        "\n",
        "- chunking이 필요한 이유\n",
        "  1. **LLM의 입력 제한**: 한 번에 처리할 수 있는 토큰 수가 제한되어 있습니다\n",
        "  2. **검색 정확도**: 작은 조각이 더 구체적인 정보를 담고 있어 검색이 정확합니다\n",
        "  3. **비용 효율**: 필요한 부분만 LLM에 전달하여 비용을 절감합니다\n",
        "\n",
        "- chunking 크기 선택 기준\n",
        "\n",
        "| Chunk 크기 | 장점 | 단점 | 적합한 경우 |\n",
        "|-----------|------|------|------------|\n",
        "| **작음** (100-300자) | 검색 정확도 높음<br>비용 효율적 | 문맥 손실 가능<br>너무 많은 chunk | 구체적인 사실 검색<br>(예: Q&A, FAQ) |\n",
        "| **중간** (300-600자) | 균형잡힌 선택<br>문맥 유지 | - | **대부분의 경우 권장** |\n",
        "| **큼** (600-1000자) | 문맥 유지 잘 됨 | 검색 정확도 하락<br>비용 증가 | 문맥이 중요한 경우<br>(예: 소설, 논문) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKs75WV7Nbb"
      },
      "source": [
        "## 4. RAG Pipeline 구현\n",
        "\n",
        "\n",
        "```\n",
        "1. 사용자 질의\n",
        "      ⬇️\n",
        "2. 질의를 임베딩으로 변환\n",
        "      ⬇️\n",
        "3. Vector DB에서 유사한 문서 검색 (Top-K)\n",
        "      ⬇️\n",
        "4. 검색된 문서를 컨텍스트로 LLM에 전달\n",
        "      ⬇️\n",
        "5. LLM이 컨텍스트 기반 답변 생성\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sn7IOPRW7MCq"
      },
      "outputs": [],
      "source": [
        "def rag_query(query: str, top_k: int = 3, show_details: bool = True):\n",
        "    \"\"\"\n",
        "    RAG 시스템을 사용하여 질의에 답변\n",
        "    \"\"\"\n",
        "    if collection.count() == 0:\n",
        "        print(\"Vector DB에 문서가 없습니다.\")\n",
        "        return None\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"사용자 질의: {query}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # STEP 1: 질의 임베딩 생성\n",
        "    if show_details:\n",
        "        print(\"1. Query를 벡터로 변환 중...\")\n",
        "\n",
        "    query_embedding = get_embedding(query)\n",
        "    if not query_embedding:\n",
        "        print(\"질의 임베딩 생성 실패\")\n",
        "        return None\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   임베딩 완료 (차원: {len(query_embedding)})\\n\")\n",
        "\n",
        "    # STEP 2: Vector DB에서 유사 문서 검색\n",
        "    if show_details:\n",
        "        print(f\"2️. Vector DB에서 Top-{top_k} 문서 검색 중...\")\n",
        "\n",
        "    try:\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=min(top_k, collection.count())\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\" 검색 실패: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    if not results['documents'][0]:\n",
        "        print(\" 검색 결과가 없습니다.\")\n",
        "        return None\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   {len(results['documents'][0])}개 문서 발견\\n\")\n",
        "        print(\"   검색 결과:\")\n",
        "        print(\"   \" + \"-\"*76)\n",
        "\n",
        "        for i, (doc, metadata, distance) in enumerate(zip(\n",
        "            results['documents'][0],\n",
        "            results['metadatas'][0],\n",
        "            results['distances'][0]\n",
        "        ), 1):\n",
        "            print(f\"\\n   [{i}위] {metadata.get('topic', 'Unknown')}\")\n",
        "            print(f\"        카테고리: {metadata.get('category', 'Unknown')}\")\n",
        "            print(f\"        유사도 거리: {distance:.4f}\")\n",
        "            print(f\"        내용: {doc[:100]}...\")\n",
        "\n",
        "        print(\"\\n   \" + \"-\"*76)\n",
        "\n",
        "    # STEP 3: 컨텍스트 구성\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"[문서 {i+1}: {metadata.get('topic', 'Unknown')}]\\n{doc}\"\n",
        "        for i, (doc, metadata) in enumerate(zip(\n",
        "            results['documents'][0],\n",
        "            results['metadatas'][0]\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # STEP 4: LLM 답변 생성\n",
        "    if show_details:\n",
        "        print(\"\\n3. LLM이 답변 생성 중...\\n\")\n",
        "\n",
        "    try:\n",
        "        prompt = f\"\"\"다음은 질문에 답변하는데 참고할 수 있는 문서들입니다:\n",
        "\n",
        "{context}\n",
        "\n",
        "위 문서들을 참고하여 다음 질문에 답변해주세요.\n",
        "답변할 때는 어떤 문서를 참고했는지 언급해주세요.\n",
        "\n",
        "질문: {query}\n",
        "\n",
        "답변은 명확하고 간결하게 한국어로 작성해주세요.\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"당신은 주어진 문서를 정확히 바탕으로 답변하는 전문 도우미입니다.\"\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"{'='*80}\")\n",
        "            print(\"LLM 답변\")\n",
        "            print(f\"{'='*80}\")\n",
        "            print(answer)\n",
        "            print(f\"\\n{'='*80}\\n\")\n",
        "\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"retrieved_docs\": results,\n",
        "            \"answer\": answer,\n",
        "            \"context\": context\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"LLM 답변 생성 실패: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u39YWq3D9Dpx"
      },
      "source": [
        "## 5. RAG vs No-RAG 실험"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GrBvlNAe9AkL"
      },
      "outputs": [],
      "source": [
        "# 실험용 질문\n",
        "test_question = \"머신러닝과 딥러닝의 구체적인 차이점을 설명해주세요.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO0Y82wO9KsV"
      },
      "source": [
        "### 1) No-RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24a4vCbF9J0S",
        "outputId": "1bc174bd-4fae-4f87-9a02-a75fd28ece7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NO-RAG\n",
            "================================================================================\n",
            "질문: 머신러닝과 딥러닝의 구체적인 차이점을 설명해주세요.\n",
            "\n",
            "답변:\n",
            "--------------------------------------------------------------------------------\n",
            "머신러닝(Machine Learning)과 딥러닝(Deep Learning)은 인공지능(AI) 분야에서 중요한 두 가지 개념입니다. 이 둘은 서로 관련이 있지만, 몇 가지 중요한 차이점이 있습니다.\n",
            "\n",
            "### 1. 정의\n",
            "- **머신러닝**: 머신러닝은 데이터에서 패턴을 학습하고 예측을 수행하는 알고리즘의 집합입니다. 머신러닝은 주로 특징(feature)을 수동으로 선택하고, 이를 기반으로 모델을 학습합니다.\n",
            "- **딥러닝**: 딥러닝은 머신러닝의 한 하위 분야로, 인공신경망(Artificial Neural Networks)을 기반으로 합니다. 딥러닝은 여러 층의 신경망을 사용하여 데이터에서 자동으로 특징을 추출합니다.\n",
            "\n",
            "### 2. 데이터 처리\n",
            "- **머신러닝**: 머신러닝 알고리즘은 일반적으로 구조화된 데이터에 잘 작동하며, 특징 선택 및 전처리가 중요합니다. 예를 들어, SVM(Support Vector Machine), 결정 트리(Decision Tree), 랜덤 포레스트(Random Forest) 등이 있습니다.\n",
            "- **딥러닝**: 딥러닝은 비구조화된 데이터(예: 이미지, 텍스트, 음성 등)를 처리하는 데 강력합니다. 신경망은 데이터의 복잡한 패턴을 자동으로 학습할 수 있습니다.\n",
            "\n",
            "### 3. 모델의 복잡성\n",
            "- **머신러닝**: 머신러닝 모델은 상대적으로 간단하며, 일반적으로 몇 개의 층과 파라미터로 구성됩니다. 따라서 학습 속도가 빠르고, 해석이 용이합니다.\n",
            "- **딥러닝**: 딥러닝 모델은 수십 개에서 수백 개의 층을 가질 수 있으며, 매우 복잡한 구조를 가지고 있습니다. 이로 인해 대량의 데이터와 계산 자원이 필요합니다.\n",
            "\n",
            "### 4. 학습 데이터의 양\n",
            "- **머신러닝**: 머신러닝 알고리즘은 상대적으로 적은 양의 데이터로도 잘 작동할 수 있습니다. 일반적으로 수천 개의 데이터 포인트로도 충분합니다.\n",
            "- **딥러닝**: 딥러닝은 대량의 데이터(수만 개 이상의 데이터 포인트)가 필요\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def no_rag_query(query: str):\n",
        "    \"\"\"RAG 없이 LLM에게 직접 질문\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"NO-RAG\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"질문: {query}\\n\")\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content\n",
        "        print(\"답변:\")\n",
        "        print(\"-\"*80)\n",
        "        print(answer)\n",
        "        print(\"=\"*80)\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"답변 생성 실패: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "no_rag_answer = no_rag_query(test_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8sJKiB79P9A"
      },
      "source": [
        "### 2) With RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1KZ9G5E9N1d",
        "outputId": "c7e0378b-328a-4650-ba48-891e498101b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "사용자 질의: 머신러닝과 딥러닝의 구체적인 차이점을 설명해주세요.\n",
            "================================================================================\n",
            "\n",
            "1. Query를 벡터로 변환 중...\n",
            "   임베딩 완료 (차원: 1536)\n",
            "\n",
            "2️. Vector DB에서 Top-3 문서 검색 중...\n",
            "   3개 문서 발견\n",
            "\n",
            "   검색 결과:\n",
            "   ----------------------------------------------------------------------------\n",
            "\n",
            "   [1위] 딥러닝\n",
            "        카테고리: AI\n",
            "        유사도 거리: 1.3589\n",
            "        내용: 심층 학습(深層學習) 또는 딥 러닝(영어: deep structured learning, deep learning 또는 hierarchical learning)은 여러 '비선형 변...\n",
            "\n",
            "   [2위] 머신러닝\n",
            "        카테고리: AI\n",
            "        유사도 거리: 1.4972\n",
            "        내용: 기계 학습(機械學習) 또는 머신 러닝(영어: machine learning, ML)은 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구이다. 방대한 데이터를 분석해 '미래를 예...\n",
            "\n",
            "   [3위] 양자 컴퓨팅\n",
            "        카테고리: Other\n",
            "        유사도 거리: 1.5997\n",
            "        내용: 양자 컴퓨터(quantum computer, 문화어: 량자 콤퓨터)는 얽힘(entanglement)이나 중첩(superposition) 같은 양자역학적인 현상을 활용하여 자료를 처...\n",
            "\n",
            "   ----------------------------------------------------------------------------\n",
            "\n",
            "3. LLM이 답변 생성 중...\n",
            "\n",
            "================================================================================\n",
            "LLM 답변\n",
            "================================================================================\n",
            "머신러닝과 딥러닝의 구체적인 차이점은 다음과 같습니다.\n",
            "\n",
            "1. **정의**:\n",
            "   - 머신러닝(문서 2): 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구로, 방대한 데이터를 분석하여 미래를 예측하는 기술입니다.\n",
            "   - 딥러닝(문서 1): 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화를 시도하는 기계 학습 알고리즘의 집합으로, 주로 사람의 사고방식을 컴퓨터에게 가르치는 분야입니다.\n",
            "\n",
            "2. **구조**:\n",
            "   - 머신러닝: 다양한 알고리즘(예: 결정 트리, 서포트 벡터 머신 등)을 사용하여 데이터를 분석하고 예측합니다.\n",
            "   - 딥러닝: 주로 심층 신경망(deep neural networks)을 사용하여 데이터의 복잡한 패턴을 학습합니다.\n",
            "\n",
            "3. **데이터 처리**:\n",
            "   - 머신러닝: 상대적으로 적은 양의 데이터로도 학습할 수 있으며, 데이터의 표현(representation)과 일반화(generalization)에 중점을 둡니다.\n",
            "   - 딥러닝: 대량의 데이터가 필요하며, 데이터의 표현을 자동으로 학습하여 더 높은 수준의 추상화를 가능하게 합니다.\n",
            "\n",
            "4. **응용 분야**:\n",
            "   - 머신러닝: 문자 인식, 스팸 필터링 등 다양한 분야에 적용됩니다.\n",
            "   - 딥러닝: 컴퓨터 비전, 음성 인식, 자연어 처리 등 최첨단 분야에 주로 사용됩니다.\n",
            "\n",
            "이러한 차이점들은 머신러닝과 딥러닝이 서로 다른 방식으로 데이터를 처리하고 학습하는 방법에 기인합니다.\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rag_result = rag_query(test_question, top_k=3, show_details=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
